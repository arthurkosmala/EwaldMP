{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0637a5d",
   "metadata": {},
   "source": [
    "# Model Training, Validation and Testing on OE62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcdd3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from ocpmodels import models\n",
    "from ocpmodels.common import logger\n",
    "from ocpmodels.common.utils import setup_logging, load_config\n",
    "from ocpmodels.datasets import LmdbDataset\n",
    "from ocpmodels.common.registry import registry\n",
    "from ocpmodels.trainers import EnergyTrainer, ForcesTrainer\n",
    "\n",
    "\n",
    "setup_logging()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026fe499",
   "metadata": {},
   "source": [
    "### Define model variant by choosing a config file\n",
    "For each model, the following variants exist: **baseline**, **variant with Ewald message passing**, **increased cutoff** and **increased embedding size**.\n",
    "\n",
    "Configs to choose from [and approximate training times in brackets]: \n",
    "- schnet_oe62_baseline.yml [~ 1h]\n",
    "- schnet_oe62_ewald.yml    [~ 4h]\n",
    "- schnet_oe62_cutoff.yml   [~ 1h]\n",
    "- schnet_oe62_embeddings.yml[~ 1.5h]\n",
    "----------------------------\n",
    "- painn_oe62_baseline.yml  [~ 10h]\n",
    "- painn_oe62_ewald.yml     [~ 14.5h]\n",
    "- painn_oe62_cutoff.yml    [~ 12h]\n",
    "- painn_oe62_embeddings.yml [~ 10h]\n",
    "----------------------------\n",
    "- dpp_oe62_baseline.yml [~ 16h]\n",
    "- dpp_oe62_ewald.yml [~ 22h]\n",
    "- dpp_oe62_cutoff.yml [~ 22h]\n",
    "- dpp_oe62_embeddings.yml [~ 19h]\n",
    "----------------------------\n",
    "- gemnet_oe62_baseline.yml [~ 1d 8h]\n",
    "- gemnet_oe62_ewald.yml [~ 1d 18h]\n",
    "- gemnet_oe62_cutoff.yml [~ 1d 18h]\n",
    "- gemnet_oe62_embeddings.yml [~ 1d 8h]\n",
    "----------------------------\n",
    "\n",
    "The above training times are based off our experience using a single `Nvidia A100` GPU. We obtained them while having intermediate evaluation runs on the test set disabled at training time. This is not the case here, so training might take slightly longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dda9925",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = \"configs_oe62\"\n",
    "#-----------Put your model variant here-----------\n",
    "config_path = os.path.join(config_dir, \"schnet_oe62_baseline.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f22354",
   "metadata": {},
   "source": [
    "### Parse config file and initialize `EnergyTrainer` object for OE62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69750d1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "conf = load_config(config_path)[0]\n",
    "task = conf[\"fixed\"][\"task\"]\n",
    "model = conf[\"fixed\"][\"model\"]\n",
    "optimizer = conf[\"fixed\"][\"optimizer\"]\n",
    "name = conf[\"fixed\"][\"name\"]\n",
    "logger = conf[\"fixed\"][\"logger\"]\n",
    "dataset = conf[\"fixed\"][\"dataset\"]\n",
    "trainer = EnergyTrainer(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    optimizer=optimizer,\n",
    "    identifier=name,\n",
    "    run_dir=\"./\",\n",
    "    is_debug=False,  # if True, do not save checkpoint, logs, or results\n",
    "    print_every=5000,\n",
    "    seed=0,  # random seed to use\n",
    "    logger=logger,  # logger of choice (tensorboard and wandb supported)\n",
    "    local_rank=0,\n",
    "    amp=False,  # whether to use PyTorch Automatic Mixed Precision\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f68db",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5195c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8009a9c4",
   "metadata": {},
   "source": [
    "### Load best checkpoint from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39432e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(\n",
    "    trainer.config[\"cmd\"][\"checkpoint_dir\"], \"best_checkpoint.pt\"\n",
    ")\n",
    "trainer = EnergyTrainer(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    optimizer=optimizer,\n",
    "    identifier=\"schnet\",\n",
    "    run_dir=\"./\",\n",
    "    # directory to save results if is_debug=False. Prediction files are saved here so be careful not to override!\n",
    "    is_debug=True,  # if True, do not save checkpoint, logs, or results\n",
    "    print_every=5000,\n",
    "    seed=0,  # random seed to use\n",
    "    logger=logger,  # logger of choice (tensorboard and wandb supported)\n",
    "    local_rank=0,\n",
    "    amp=False,  # use PyTorch Automatic Mixed Precision (faster training and less memory usage)\n",
    ")\n",
    "trainer.load_checkpoint(checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5995c135",
   "metadata": {},
   "source": [
    "### Validate or test model\n",
    "Replace the argument below by `split=\"val\"` to use the OE62 validation split instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90f9944",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.validate(split=\"test\")\n",
    "results = {key: val[\"metric\"] for key, val in metrics.items()}\n",
    "print(f\"Results for configuration {name}: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420326a1",
   "metadata": {},
   "source": [
    "# Model Training and Validation on OC20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b0250",
   "metadata": {},
   "source": [
    "On OC20, only validation can be done locally. To generate results on the test set, follow the instructions on https://github.com/Open-Catalyst-Project/ocp to obtain files for submission on eval.ai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb1921",
   "metadata": {},
   "source": [
    "### Define model variant by choosing a config file\n",
    "For each model, the following variants exist: **baseline**, **variant with Ewald message passing**, **increased cutoff**.\n",
    "\n",
    "Configs to choose from [and approximate training times in brackets]: \n",
    "- schnet_oc20_baseline.yml [~ 1d 4h]\n",
    "- schnet_oc20_ewald.yml [~ 2d 18h]\n",
    "- schnet_oc20_cutoff.yml [~ 2d 22h]\n",
    "----------------------------\n",
    "- painn_oc20_baseline.yml [~ 2d 11h]\n",
    "- painn_oc20_ewald.yml [~ 2d 17h]\n",
    "- painn_oc20_cutoff.yml [~ 3d 7h]\n",
    "----------------------------\n",
    "- dpp_oc20_baseline.yml [~ 6d]\n",
    "- dpp_oc20_ewald.yml [~ 6d 12h]\n",
    "- dpp_oc20_cutoff.yml [~6d 15h]\n",
    "----------------------------\n",
    "- gemnet_oc20_baseline.yml [~ 10d 2h]\n",
    "- gemnet_oc20_ewald.yml [~ 11d 2h]\n",
    "- gemnet_oc20_cutoff.yml [~ 11d 4h]\n",
    "----------------------------\n",
    "The above training times are based off our experience using a single `Nvidia A100` GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab38ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = \"configs_oc20\"\n",
    "#-----------Put your model variant here-----------\n",
    "config_path = os.path.join(config_dir, \"schnet_oc20_baseline.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06e644",
   "metadata": {},
   "source": [
    "### Parse config file and initialize `ForcesTrainer` object for OC20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a05fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "conf = load_config(config_path)[0]\n",
    "task = conf[\"fixed\"][\"task\"]\n",
    "model = conf[\"fixed\"][\"model\"]\n",
    "optimizer = conf[\"fixed\"][\"optimizer\"]\n",
    "name = conf[\"fixed\"][\"name\"]\n",
    "logger = conf[\"fixed\"][\"logger\"]\n",
    "# conf[\"fixed\"][\"dataset_train\"] contains the training set and the \n",
    "# combination of all four validation splits\n",
    "dataset = conf[\"fixed\"][\"dataset_train\"]\n",
    "# four individual validation splits \n",
    "#(adsorbate, catalyst, none or both have out-of-distribution composition)\n",
    "dataset_id = conf[\"fixed\"][\"dataset_id\"]\n",
    "dataset_ood_ads = conf[\"fixed\"][\"dataset_ood_ads\"]\n",
    "dataset_ood_cat = conf[\"fixed\"][\"dataset_ood_cat\"]\n",
    "dataset_ood_both = conf[\"fixed\"][\"dataset_ood_both\"]\n",
    "trainer = ForcesTrainer(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    optimizer=optimizer,\n",
    "    identifier=name,\n",
    "    run_dir=\"./\",\n",
    "    is_debug=False,  # if True, do not save checkpoint, logs, or results\n",
    "    print_every=5000,\n",
    "    seed=0,  # random seed to use\n",
    "    logger=logger,  # logger of choice (tensorboard and wandb supported)\n",
    "    local_rank=0,\n",
    "    amp=False,  # whether to use PyTorch Automatic Mixed Precision\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10be049",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ecd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1176d86d",
   "metadata": {},
   "source": [
    "### Load best checkpoint from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(\n",
    "    trainer.config[\"cmd\"][\"checkpoint_dir\"], \"best_checkpoint.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1072b7",
   "metadata": {},
   "source": [
    "### Validate on val-id\n",
    "Validation split where both the adsorbate and catalyst compositions are in-distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eee677",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer = ForcesTrainer(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    dataset=dataset_id,\n",
    "    optimizer=optimizer,\n",
    "    identifier=\"validate_id\",\n",
    "    run_dir=\"./\",\n",
    "    # directory to save results if is_debug=False. Prediction files are saved here so be careful not to override!\n",
    "    is_debug=True,  # if True, do not save checkpoint, logs, or results, set to False if you want to test not validate (results file needed)\n",
    "    print_every=5000,\n",
    "    seed=0,  # random seed to use\n",
    "    logger=logger,  # logger of choice (tensorboard and wsqueueandb supported)\n",
    "    local_rank=0,\n",
    "    amp=False,  # use PyTorch Automatic Mixed Precision (faster training and less memory usage)\n",
    ")\n",
    "\n",
    "trainer.load_checkpoint(checkpoint_path=checkpoint_path)\n",
    "metrics = trainer.validate()\n",
    "results_id = {key: val[\"metric\"] for key, val in metrics.items()}\n",
    "print(f\"val-id results for configuration {name}: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d577bb",
   "metadata": {},
   "source": [
    "### Validate on val-ood-ads\n",
    "Validation split where the adsorbate compositions are out-of-distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ForcesTrainer(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    dataset=dataset_ood_ads,\n",
    "    optimizer=optimizer,\n",
    "    identifier=\"validate_ood_ads\",\n",
    "    run_dir=\"./\",\n",
    "    # directory to save results if is_debug=False. Prediction files are saved here so be careful not to override!\n",
    "    is_debug=True,  # if True, do not save checkpoint, logs, or results, set to False if you want to test not validate (results file needed)\n",
    "    print_every=5000,\n",
    "    seed=0,  # random seed to use\n",
    "    logger=logger,  # logger of choice (tensorboard and wsqueueandb supported)\n",
    "    local_rank=0,\n",
    "    amp=False,  # use PyTorch Automatic Mixed Precision (faster training and less memory usage)\n",
    ")\n",
    "\n",
    "trainer.load_checkpoint(checkpoint_path=checkpoint_path)\n",
    "metrics = trainer.validate()\n",
    "results_id = {key: val[\"metric\"] for key, val in metrics.items()}\n",
    "print(f\"val-ood-ads results for configuration {name}: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf59a40",
   "metadata": {},
   "source": [
    "### Validate on val-ood-cat\n",
    "Validation split where the catalyst compositions are out-of-distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a59991",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ForcesTrainer(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    dataset=dataset_ood_cat,\n",
    "    optimizer=optimizer,\n",
    "    identifier=\"validate_ood_cat\",\n",
    "    run_dir=\"./\",\n",
    "    # directory to save results if is_debug=False. Prediction files are saved here so be careful not to override!\n",
    "    is_debug=True,  # if True, do not save checkpoint, logs, or results, set to False if you want to test not validate (results file needed)\n",
    "    print_every=5000,\n",
    "    seed=0,  # random seed to use\n",
    "    logger=logger,  # logger of choice (tensorboard and wsqueueandb supported)\n",
    "    local_rank=0,\n",
    "    amp=False,  # use PyTorch Automatic Mixed Precision (faster training and less memory usage)\n",
    ")\n",
    "\n",
    "trainer.load_checkpoint(checkpoint_path=checkpoint_path)\n",
    "metrics = trainer.validate()\n",
    "results_id = {key: val[\"metric\"] for key, val in metrics.items()}\n",
    "print(f\"val-ood-cat results for configuration {name}: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f277008",
   "metadata": {},
   "source": [
    "### Validate on val-ood-both\n",
    "Validation split where both the adsorbate and catalyst compositions are out-of-distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ea9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ForcesTrainer(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    dataset=dataset_ood_both,\n",
    "    optimizer=optimizer,\n",
    "    identifier=\"validate_ood_both\",\n",
    "    run_dir=\"./\",\n",
    "    # directory to save results if is_debug=False. Prediction files are saved here so be careful not to override!\n",
    "    is_debug=True,  # if True, do not save checkpoint, logs, or results, set to False if you want to test not validate (results file needed)\n",
    "    print_every=5000,\n",
    "    seed=0,  # random seed to use\n",
    "    logger=logger,  # logger of choice (tensorboard and wsqueueandb supported)\n",
    "    local_rank=0,\n",
    "    amp=False,  # use PyTorch Automatic Mixed Precision (faster training and less memory usage)\n",
    ")\n",
    "\n",
    "trainer.load_checkpoint(checkpoint_path=checkpoint_path)\n",
    "metrics = trainer.validate()\n",
    "results_id = {key: val[\"metric\"] for key, val in metrics.items()}\n",
    "print(f\"val-ood-both results for configuration {name}: {results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
