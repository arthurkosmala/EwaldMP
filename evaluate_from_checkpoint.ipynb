{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "961eec24",
   "metadata": {},
   "source": [
    "# Model Validation / Testing on OE62 from Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8966deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from ocpmodels import models\n",
    "from ocpmodels.common import logger\n",
    "from ocpmodels.common.utils import setup_logging, load_config\n",
    "from ocpmodels.datasets import LmdbDataset\n",
    "from ocpmodels.common.registry import registry\n",
    "from ocpmodels.trainers import EnergyTrainer, ForcesTrainer\n",
    "\n",
    "\n",
    "setup_logging()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af60a6b6",
   "metadata": {},
   "source": [
    "### Define model variant by choosing a config file\n",
    "For each model, the following variants exist: **baseline**, **variant with Ewald message passing**, **increased cutoff** and **increased embedding size**.\n",
    "\n",
    "Configs to choose from: \n",
    "- schnet_oe62_baseline.yml\n",
    "- schnet_oe62_ewald.yml\n",
    "- schnet_oe62_cutoff.yml\n",
    "- schnet_oe62_embeddings.yml\n",
    "----------------------------\n",
    "- painn_oe62_baseline.yml\n",
    "- painn_oe62_ewald.yml\n",
    "- painn_oe62_cutoff.yml\n",
    "- painn_oe62_embeddings.yml\n",
    "----------------------------\n",
    "- dpp_oe62_baseline.yml\n",
    "- dpp_oe62_ewald.yml\n",
    "- dpp_oe62_cutoff.yml\n",
    "- dpp_oe62_embeddings.yml\n",
    "----------------------------\n",
    "- gemnet_oe62_baseline.yml\n",
    "- gemnet_oe62_ewald.yml\n",
    "- gemnet_oe62_cutoff.yml\n",
    "- gemnet_oe62_embeddings.yml\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7302e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = \"configs_runtime_oe62\"\n",
    "#-----------Put your model variant here-----------\n",
    "config_path = os.path.join(config_dir, \"schnet_oc20_baseline.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29e744",
   "metadata": {},
   "source": [
    "### Parse config file and initialize `EnergyTrainer` object for OE62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378649d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "conf = load_config(config_path)[0]\n",
    "task = conf[\"fixed\"][\"task\"]\n",
    "model = conf[\"fixed\"][\"model\"]\n",
    "optimizer = conf[\"fixed\"][\"optimizer\"]\n",
    "name = conf[\"fixed\"][\"name\"]\n",
    "logger = conf[\"fixed\"][\"logger\"]\n",
    "dataset = conf[\"fixed\"][\"dataset\"]\n",
    "trainer = EnergyTrainer(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    optimizer=optimizer,\n",
    "    identifier=name,\n",
    "    run_dir=\"./\",\n",
    "    is_debug=True,  # if True, do not save checkpoint, logs, or results\n",
    "    print_every=5000,\n",
    "    seed=0,  # random seed to use\n",
    "    logger=logger,  # logger of choice (tensorboard and wandb supported)\n",
    "    local_rank=0,\n",
    "    amp=False,  # whether to use PyTorch Automatic Mixed Precision\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effffad1",
   "metadata": {},
   "source": [
    "### Load checkpoint file\n",
    "\n",
    "After training your model (using the provided `seml` commands, or the training notebook from this repository, paste the path to your checkpoint file below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae65422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = \"checkpoints\"\n",
    "checkpoint_path = os.path.join(\n",
    "    checkpoint_dir,\n",
    "    \"[your_checkpoint_dir]\",\n",
    "    \"best_checkpoint.pt\")\n",
    "trainer.load_checkpoint(checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc4dfe5",
   "metadata": {},
   "source": [
    "### Validate or test model\n",
    "Replace the argument below by `split=\"val\"` to use the OE62 validation split instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7459b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.validate(split=\"test\")\n",
    "results = {key: val[\"metric\"] for key, val in metrics.items()}\n",
    "print(f\"Results for configuration {name}: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45729cf",
   "metadata": {},
   "source": [
    "# Model Validation on OC20 from Checkpoint\n",
    "\n",
    "On OC20, only validation can be done locally. To generate results on the test set, follow the instructions on https://github.com/Open-Catalyst-Project/ocp to obtain files for submission on eval.ai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e0261f",
   "metadata": {},
   "source": [
    "### Define model variant by choosing a config file\n",
    "For each model, the following variants exist: **baseline**, **variant with Ewald message passing**, **increased cutoff**.\n",
    "\n",
    "Configs to choose from: \n",
    "- schnet_oc20_baseline.yml\n",
    "- schnet_oc20_ewald.yml\n",
    "- schnet_oc20_cutoff.yml\n",
    "----------------------------\n",
    "- painn_oc20_baseline.yml\n",
    "- painn_oc20_ewald.yml\n",
    "- painn_oc20_cutoff.yml\n",
    "----------------------------\n",
    "- dpp_oc20_baseline.yml\n",
    "- dpp_oc20_ewald.yml\n",
    "- dpp_oc20_cutoff.yml\n",
    "----------------------------\n",
    "- gemnet_oc20_baseline.yml\n",
    "- gemnet_oc20_ewald.yml\n",
    "- gemnet_oc20_cutoff.yml\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37070ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = \"configs_oc20\"\n",
    "#-----------Put your model variant here-----------\n",
    "config_path = os.path.join(config_dir,\"schnet_oc20_baseline.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b05241",
   "metadata": {},
   "source": [
    "### Parse config file and initialize `ForcesTrainer` object for OC20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cd710c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for split in [\"id\", \"ood_ads\", \"ood_cat\", \"ood_both\"]:\n",
    "    torch.cuda.empty_cache()\n",
    "    conf = load_config(config_path)[0]\n",
    "    task = conf[\"fixed\"][\"task\"]\n",
    "    model = conf[\"fixed\"][\"model\"]\n",
    "    optimizer = conf[\"fixed\"][\"optimizer\"]\n",
    "    name = conf[\"fixed\"][\"name\"]\n",
    "    logger = conf[\"fixed\"][\"logger\"]\n",
    "    # Replace dataset_train by dataset_id, dataset_ood_ads, dataset_ood_both or\n",
    "    # dataset_ood_cat to validate only on a particular subsplit (note that the\n",
    "    # validation set subsampling option is currently just available on the\n",
    "    # combination of all four splits, specified by putting dataset_train below)\n",
    "    dataset = conf[\"fixed\"][f\"dataset_{split}\"]\n",
    "    trainer = ForcesTrainer(\n",
    "        task=task,\n",
    "        model=model,\n",
    "        dataset=dataset,\n",
    "        optimizer=optimizer,\n",
    "        identifier=f\"{name}_{split}_test1\",\n",
    "        run_dir=\"./\",\n",
    "        is_debug=False,  # if True, do not save checkpoint, logs, or results\n",
    "        print_every=5000,\n",
    "        seed=0,  # random seed to use\n",
    "        logger=logger,  # logger of choice (tensorboard and wandb supported)\n",
    "        local_rank=0,\n",
    "        amp=False,  # whether to use PyTorch Automatic Mixed Precision\n",
    "    )\n",
    "    \n",
    "    trainer.train_dataset.close_db()\n",
    "    if trainer.config.get(\"val_dataset\", False):\n",
    "        trainer.val_dataset.close_db()\n",
    "    if trainer.config.get(\"test_dataset\", False):\n",
    "        trainer.test_dataset.close_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745ed49",
   "metadata": {},
   "source": [
    "### Load checkpoint file\n",
    "\n",
    "After training your model by using the provided `seml` commands, paste the path to your checkpoint file below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9769edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = \"checkpoints\"\n",
    "checkpoint_path = os.path.join(\n",
    "    checkpoint_dir,\n",
    "    \"[your_checkpoint_dir]\",\n",
    "    \"best_checkpoint.pt\")\n",
    "trainer.load_checkpoint(checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a855f57",
   "metadata": {},
   "source": [
    "### Validate model\n",
    "The setting below validates on a 1% subsample of all validation structures, drawn evenly from all four splits.\n",
    "Replace the argument below by `split=\"val\"` to use the full validation set (all four splits) instead (as this takes 100x as long, we recommend doing it overnight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.validate(split=\"val_sub\") #put split=\"val\" for full validation set\n",
    "results = {key: val[\"metric\"] for key, val in metrics.items()}\n",
    "print(f\"Results for configuration {name}: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8878898e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
